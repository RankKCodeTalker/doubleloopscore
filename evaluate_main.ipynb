{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluated_model\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"question\": \"\",\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutils import io\n",
    "data = io.jsonload(\"data/eval.json\")\n",
    "evaluated_path = \"evaluated_models/llama2-7bchat.json\"\n",
    "evaluated_model = io.jsonload(evaluated_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [03:55,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.double_loop import double_loop_match, double_loop_score\n",
    "from tqdm import tqdm\n",
    "assert len(data)==len(evaluated_model)\n",
    "for data_unit, evaluated_model_unit in zip(data, evaluated_model):\n",
    "    assert data_unit['question'] == evaluated_model_unit['question']\n",
    "result = {\n",
    "    \"path\": evaluated_path,\n",
    "    \"average_score\": 0,\n",
    "    \"logs\": []\n",
    "}\n",
    "sum_score = 0\n",
    "for data_unit, evaluated_model_unit in tqdm(zip(data, evaluated_model)):\n",
    "    question = data_unit['question']\n",
    "    evaluated_answer = evaluated_model_unit['answer']\n",
    "    scored_answers = [unit['answer'] for unit in data_unit['answers']]\n",
    "    ys = [unit['score'] for unit in data_unit['answers']]\n",
    "    xc, xs = double_loop_match(question, evaluated_answer, scored_answers)\n",
    "    yc = double_loop_score(xc, xs, ys)\n",
    "    sum_score += yc\n",
    "    result['logs'].append({\n",
    "        \"xc\": xc,\n",
    "        \"xs\": xs,\n",
    "        \"yc\": yc\n",
    "    })\n",
    "result['average_score'] = sum_score / len(data)\n",
    "io.jsondump(result, evaluated_path+\".log2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>language</th>\n",
       "      <th>memory</th>\n",
       "      <th>security</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4.json</td>\n",
       "      <td>93.024160</td>\n",
       "      <td>89.301091</td>\n",
       "      <td>90.456978</td>\n",
       "      <td>88.988338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baichuan7bchat.json</td>\n",
       "      <td>87.522701</td>\n",
       "      <td>82.538491</td>\n",
       "      <td>90.138886</td>\n",
       "      <td>85.058719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3.5.json</td>\n",
       "      <td>89.424512</td>\n",
       "      <td>82.980503</td>\n",
       "      <td>72.584380</td>\n",
       "      <td>83.620583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama2-7bchat.json</td>\n",
       "      <td>94.168061</td>\n",
       "      <td>70.285417</td>\n",
       "      <td>96.405312</td>\n",
       "      <td>83.261408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwen7bchat.json</td>\n",
       "      <td>85.398684</td>\n",
       "      <td>82.105599</td>\n",
       "      <td>82.410785</td>\n",
       "      <td>82.303568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatglm-6b.json</td>\n",
       "      <td>82.685226</td>\n",
       "      <td>72.935230</td>\n",
       "      <td>75.752836</td>\n",
       "      <td>76.439790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm2-6b.json</td>\n",
       "      <td>82.980736</td>\n",
       "      <td>65.797183</td>\n",
       "      <td>82.601787</td>\n",
       "      <td>75.068995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   language     memory   security    average\n",
       "4            gpt4.json  93.024160  89.301091  90.456978  88.988338\n",
       "0  baichuan7bchat.json  87.522701  82.538491  90.138886  85.058719\n",
       "3          gpt3.5.json  89.424512  82.980503  72.584380  83.620583\n",
       "5   llama2-7bchat.json  94.168061  70.285417  96.405312  83.261408\n",
       "6      qwen7bchat.json  85.398684  82.105599  82.410785  82.303568\n",
       "1      chatglm-6b.json  82.685226  72.935230  75.752836  76.439790\n",
       "2     chatglm2-6b.json  82.980736  65.797183  82.601787  75.068995"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from myutils import io\n",
    "import os\n",
    "def average(k: list):\n",
    "    return sum(k)/len(k)\n",
    "def getspan(a, b):\n",
    "    return list(range(a, b))\n",
    "def get_slice(a: list, indexes: list):\n",
    "    result = []\n",
    "    for i in indexes:\n",
    "        result.append(a[i])\n",
    "    return result\n",
    "span1 = getspan(0, 30) + getspan(50, 60) + getspan(80, 90)\n",
    "span2 = getspan(30, 50) + getspan(60, 70) + getspan(90, 108)\n",
    "span3 = getspan(108, 122)\n",
    "result = []\n",
    "for file in os.listdir(\"evaluated_models\"):\n",
    "    if file.endswith(\".log2\"):\n",
    "        filepath = os.path.join(\"evaluated_models\", file)\n",
    "        data = io.jsonload(filepath)\n",
    "        result.append({\n",
    "            'model': file.replace('.log2', ''),\n",
    "            'language': average([unit['yc'] for unit in get_slice(data['logs'], span1)]),\n",
    "            'memory': average([unit['yc'] for unit in get_slice(data['logs'], span2)]),\n",
    "            'security': average([unit['yc'] for unit in get_slice(data['logs'], span3)]),\n",
    "            'average': data['average_score']\n",
    "        })\n",
    "pd.DataFrame(result).sort_values('average', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
